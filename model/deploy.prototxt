name: "CNN_Net"
layer{
    name: "data"
    type: "Input"
    top: "data"
    input_param{
	shape{
    	    dim: 1
	    dim: 1
	    dim: 96
	    dim: 96
        }
    }
}

layer{
    name: "conv1"
    type: "Convolution"
    bottom: "data"
    top: "conv1"
    convolution_param{
	num_output: 96
        kernel_size: 3
	pad: 1 
	weight_filler{
	    type: "msra"	
	}
	bias_term: false
    }
}

layer{
    name: "bn_conv1"
    type: "BatchNorm"
    bottom: "conv1"
    top: "conv1"
    batch_norm_param{
        use_global_stats: true
	moving_average_fraction: 0.9
    }
}

layer {
    name: "scale_conv1"
    type: "Scale"
    bottom: "conv1"
    top: "conv1"
    scale_param {
        bias_term: true
    }
}

layer{
    name: "relu_conv1"
    type: "PReLU"
    bottom: "conv1"
    top: "conv1"
}

layer{
    name: "pool1"
    type: "Pooling"
    bottom: "conv1"
    top: "pool1"
    pooling_param{
	kernel_size: 3
	pool: MAX
	stride: 2
    }
}

layer{
    name: "conv2"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2"
    convolution_param{
	num_output: 128
	kernel_size: 3
	pad: 1
	weight_filler{
	    type: "msra"
	}
	bias_term: false
    }
}

layer{
    name: "bn_conv2"
    type: "BatchNorm"
    bottom: "conv2"
    top: "conv2"
    batch_norm_param{
        use_global_stats: true
	moving_average_fraction: 0.9
    }
}

layer {
    name: "scale_conv2"
    type: "Scale"
    bottom: "conv2"
    top: "conv2"
    scale_param {
        bias_term: true
    }
}

layer{
    name: "relu_conv2"
    type: "PReLU"
    bottom: "conv2"
    top: "conv2"
}

layer{
    name: "pool2"
    type: "Pooling"
    bottom: "conv2"
    top: "pool2"
    pooling_param{
	kernel_size: 3
	pool: MAX
	stride: 2
    }
}

layer{
    name: "conv3"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3"
    convolution_param{
	num_output: 160
	kernel_size: 3
	pad: 1
	weight_filler{
	    type: "msra"
	}
	bias_term: false
    }
}

layer{
    name: "bn_conv3"
    type: "BatchNorm"
    bottom: "conv3"
    top: "conv3"
    batch_norm_param{
        use_global_stats: true
	moving_average_fraction: 0.9
    }
}

layer {
    name: "scale_conv3"
    type: "Scale"
    bottom: "conv3"
    top: "conv3"
    scale_param {
        bias_term: true
    }
}

layer{
    name: "relu_conv3"
    type: "PReLU"
    bottom: "conv3"
    top: "conv3"
}

layer{
    name: "pool3"
    type: "Pooling"
    bottom: "conv3"
    top: "pool3"
    pooling_param{
	kernel_size: 3
	pool: MAX
	stride: 2
    }
}

layer{
    name: "conv4_1"
    type: "Convolution"
    bottom: "pool3"
    top: "conv4_1"
    convolution_param{
	num_output: 256
	kernel_size: 3
	pad: 1
	weight_filler{
	    type: "msra"
        }
	bias_term: false
    }
}

layer{
    name: "bn_conv4_1"
    type: "BatchNorm"
    bottom: "conv4_1"
    top: "conv4_1"
    batch_norm_param{
        use_global_stats: true
	moving_average_fraction: 0.9
    }
}

layer {
    name: "scale_conv4_1"
    type: "Scale"
    bottom: "conv4_1"
    top: "conv4_1"
    scale_param {
        bias_term: true
    }
}

layer{
    name: "relu_conv4_1"
    type: "PReLU"
    bottom: "conv4_1"
    top: "conv4_1"
}

layer{
    name: "conv4_2"
    type: "Convolution"
    bottom: "conv4_1"
    top: "conv4_2"
    convolution_param{
	num_output: 256
	kernel_size: 3
	pad: 1
	weight_filler{
	    type: "msra"
        }
	bias_term: false
    }
}

layer{
    name: "bn_conv4_2"
    type: "BatchNorm"
    bottom: "conv4_2"
    top: "conv4_2"
    batch_norm_param{
        use_global_stats: true
	moving_average_fraction: 0.9
    }
}

layer {
    name: "scale_conv4_2"
    type: "Scale"
    bottom: "conv4_2"
    top: "conv4_2"
    scale_param {
        bias_term: true
    }
}

layer{
    name: "relu_conv4_2"
    type: "PReLU"
    bottom: "conv4_2"
    top: "conv4_2"
}

layer{
    name: "pool4"
    type: "Pooling"
    bottom: "conv4_2"
    top: "pool4"
    pooling_param{
	kernel_size: 3
	pool: MAX
	stride: 2
    }
}

layer{
    name: "conv5_1"
    type: "Convolution"
    bottom: "pool4"
    top: "conv5_1"
    convolution_param{
	num_output: 384
	kernel_size: 3
	pad: 1
	weight_filler{
	    type: "msra"
        }
	bias_term: false
    }
}

layer{
    name: "bn_conv5_1"
    type: "BatchNorm"
    bottom: "conv5_1"
    top: "conv5_1"
    batch_norm_param{
        use_global_stats: true
	moving_average_fraction: 0.9
    }
}

layer {
    name: "scale_conv5_1"
    type: "Scale"
    bottom: "conv5_1"
    top: "conv5_1"
    scale_param {
        bias_term: true
    }
}

layer{
    name: "relu_conv5_1"
    type: "PReLU"
    bottom: "conv5_1"
    top: "conv5_1"
}

layer{
    name: "conv5_2"
    type: "Convolution"
    bottom: "conv5_1"
    top: "conv5_2"
    convolution_param{
	num_output: 384
	kernel_size: 3
	pad: 1
	weight_filler{
	    type: "msra"
        }
	bias_term: false
    }
}

layer{
    name: "bn_conv5_2"
    type: "BatchNorm"
    bottom: "conv5_2"
    top: "conv5_2"
    batch_norm_param{
        use_global_stats: true
	moving_average_fraction: 0.9
    }
}

layer {
    name: "scale_conv5_2"
    type: "Scale"
    bottom: "conv5_2"
    top: "conv5_2"
    scale_param {
        bias_term: true
    }
}

layer{
    name: "relu_conv5_2"
    type: "PReLU"
    bottom: "conv5_2"
    top: "conv5_2"
}

layer{
    name: "pool5"
    type: "Pooling"
    bottom: "conv5_2"
    top: "pool5"
    pooling_param{
	kernel_size: 3
	pool: MAX
	stride: 2
    }
}

layer{
    name: "fc1024_ft"
    type: "InnerProduct"
    bottom: "pool5"
    top: "fc1024_ft"
    param{
        lr_mult: 10
        decay_mult: 1
    }
    param{
	lr_mult: 20
	decay_mult: 1
    }
    inner_product_param{
	num_output: 1024
	weight_filler {
            type: "msra"
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}

layer{
    name: "bn_fc1024"
    type: "BatchNorm"
    bottom: "fc1024_ft"
    top: "fc1024_ft"
    batch_norm_param{
        use_global_stats: true
	moving_average_fraction: 0.9
    }
}

layer {
    name: "scale_fc1024"
    type: "Scale"
    bottom: "fc1024_ft"
    top: "fc1024_ft"
    scale_param {
        bias_term: true
    }
}

layer{
    name: "drop"
    type: "Dropout"
    bottom: "fc1024_ft"
    top: "fc1024_ft"
    dropout_param{
	dropout_ratio: 0.5
    }
}

layer{
    name: "relu_fc1024"
    type: "PReLU"
    bottom: "fc1024_ft"
    top: "fc1024_ft"
}

layer{
    name: "fc10"
    type: "InnerProduct"
    bottom: "fc1024_ft"
    top: "fc10"
    param{
        lr_mult: 10
        decay_mult: 1
    }
    param{
	lr_mult: 20
	decay_mult: 1
    }
    inner_product_param{
	num_output: 10
        weight_filler{
	    type: "msra"
        }
	bias_filler{
	    type: "constant"
	    value: 0
	}
    }
}

layer{
    name: "prob"
    type: "Softmax"
    bottom: "fc10"
    top: "prob"
}


